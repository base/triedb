use crate::{
    config::{Config, logger::Logger},
    context::TransactionContext,
    meta::{MetadataManager, OpenMetadataError},
    page::{PageError, PageId, PageManager},
    storage::engine::{self, StorageEngine},
    transaction::{Transaction, TransactionError, TransactionManager, RO, RW},
};
use alloy_primitives::B256;
use parking_lot::Mutex;
use std::{
    fs::File,
    io,
    path::{Path, PathBuf},
};

static LOGGER: Logger = Logger;

#[derive(Debug)]
pub struct Database {
    pub(crate) storage_engine: StorageEngine,
    pub(crate) transaction_manager: Mutex<TransactionManager>,
    cfg: Config,
}

#[must_use]
#[derive(Default, Debug)]
pub struct DatabaseOptions {
    create: bool,
    create_new: bool,
    wipe: bool,
    meta_path: Option<PathBuf>,
}

#[derive(Debug)]
pub enum Error {
    PageError(PageError),
    EngineError(engine::Error),
}

#[derive(Debug)]
pub enum OpenError {
    PageError(PageError),
    MetadataError(OpenMetadataError),
    IO(io::Error),
}

impl DatabaseOptions {
    /// Sets the option to create a new database, or open it if it already exists.
    ///
    /// The semantics of this method are equivalent to [`std::fs::OpenOptions::create()`].
    pub fn create(&mut self, create: bool) -> &mut Self {
        self.create = create;
        self
    }

    /// Sets the option to create a new database, failing if it already exists.
    ///
    /// The semantics of this method are equivalent to [`std::fs::OpenOptions::create_new()`].
    ///
    /// If `create_new(true)` is set, then [`create()`](Self::create) and [`wipe()`](Self::wipe)
    /// are ignored.
    pub fn create_new(&mut self, create_new: bool) -> &mut Self {
        self.create_new = create_new;
        self
    }

    /// Sets the option to erase the database if it gets successfully opened.
    pub fn wipe(&mut self, wipe: bool) -> &mut Self {
        self.wipe = wipe;
        self
    }

    /// Specifies the path of the metadata file.
    ///
    /// By default, the metadata file path is generated by appending `".meta"` to the database file
    /// path.
    pub fn meta_path(&mut self, meta_path: impl Into<PathBuf>) -> &mut Self {
        self.meta_path = Some(meta_path.into());
        self
    }

    /// Opens the database file at the given path.
    pub fn open(&self, db_path: impl AsRef<Path>, cfg: &Config) -> Result<Database, OpenError> {
        let db_path = db_path.as_ref();
        let meta_path = self.meta_path.clone().unwrap_or_else(|| {
            let mut meta_path = db_path.to_path_buf();
            meta_path.as_mut_os_string().push(".meta");
            meta_path
        });

        Database::open_with_options(db_path, meta_path, self, cfg)
    }
}

impl Database {
    pub fn open(db_path: impl AsRef<Path>, cfg: &Config) -> Result<Self, OpenError> {
        Self::options().open(db_path, cfg)
    }

    pub fn create_new(db_path: impl AsRef<Path>, cfg: &Config) -> Result<Self, OpenError> {
        Self::options().create_new(true).open(db_path, cfg)
    }

    pub fn options() -> DatabaseOptions {
        DatabaseOptions::default()
    }

    fn open_with_options(
        db_path: impl AsRef<Path>,
        meta_path: impl AsRef<Path>,
        opts: &DatabaseOptions,
        cfg: &Config,
    ) -> Result<Self, OpenError> {
        // Initialize logger first
        Self::init_logger(cfg);

        let db_path = db_path.as_ref();
        let meta_path = meta_path.as_ref();

        let meta_file = File::options()
            .read(true)
            .write(true)
            .create(opts.create)
            .create_new(opts.create_new)
            .truncate(false)
            .open(meta_path)
            .map_err(OpenError::IO)?;
        let mut meta_manager =
            MetadataManager::from_file(meta_file).map_err(OpenError::MetadataError)?;

        if opts.wipe {
            meta_manager.wipe().map_err(OpenError::IO)?
        }

        let page_count = meta_manager.active_slot().page_count();
        let page_manager = PageManager::options()
            .create(opts.create)
            .create_new(opts.create_new)
            .wipe(opts.wipe)
            .page_count(page_count)
            .open(db_path)
            .map_err(OpenError::PageError)?;

        Ok(Self::new(StorageEngine::new(page_manager, meta_manager), cfg))
    }

    /// Set global logger to our configurable logger that will use the log level from the config.
    fn init_logger(cfg: &Config) {
        if let Err(e) = log::set_logger(&LOGGER) {
            eprintln!("Failed to set logger: {e:?}");
        }
        log::set_max_level(cfg.log_level);
    }

    pub fn new(storage_engine: StorageEngine, cfg: &Config) -> Self {
        Self {
            storage_engine,
            transaction_manager: Mutex::new(TransactionManager::new()),
            cfg: cfg.clone(),
        }
    }

    pub fn close(self) -> io::Result<()> {
        self.storage_engine.close()
    }

    pub fn print_page<W: io::Write>(self, buf: W, page_id: Option<PageId>) -> Result<(), Error> {
        let context = self.storage_engine.read_context();
        // TODO: Must use `expect()` because `storage::engine::Error` and `database::Error` are not
        // compatible. There's probably no reason to use two different error enums here, so maybe
        // we should unify them. Or maybe we could just rely on `std::io::Error`.
        self.storage_engine.print_page(&context, buf, page_id).expect("write failed");
        Ok(())
    }

    pub fn root_page_info<W: io::Write>(
        self,
        mut buf: W,
        file_path: impl AsRef<Path>,
    ) -> Result<(), OpenError> {
        let db_file_path = file_path.as_ref();

        let mut meta_file_path = db_file_path.to_path_buf();
        meta_file_path.as_mut_os_string().push(".meta");
        let mut meta_manager =
            MetadataManager::open(meta_file_path).map_err(OpenError::MetadataError)?;

        let page_count = meta_manager.active_slot().page_count();
        let active_slot = meta_manager.active_slot();
        let root_node_page_id = active_slot.root_node_page_id();
        let orphaned_page_list = meta_manager.orphan_pages().iter().collect::<Vec<_>>();

        writeln!(buf, "Root Node Page ID: {root_node_page_id:?}").expect("write failed");

        //root subtrie pageID
        writeln!(buf, "Total Page Count: {page_count:?}").expect("write failed");

        //orphaned pages list (grouped by page)
        writeln!(buf, "Orphaned Pages: {orphaned_page_list:?}").expect("write failed");

        Ok(())
    }

    pub fn print_statistics<W: io::Write>(self, buf: W) -> Result<(), Error> {
        let context = self.storage_engine.read_context();
        self.storage_engine.debug_statistics(&context, buf).expect("write failed");
        Ok(())
    }

    pub fn begin_rw(&self) -> Result<Transaction<'_, RW>, TransactionError> {
        let context = self.storage_engine.write_context();
        let min_snapshot_id = self.transaction_manager.lock().begin_rw(context.snapshot_id)?;
        if min_snapshot_id > 0 {
            self.storage_engine.unlock(min_snapshot_id - 1);
        }
        Ok(Transaction::new(context, self))
    }

    pub fn begin_ro(&self) -> Result<Transaction<'_, RO>, TransactionError> {
        let context = self.storage_engine.read_context();
        self.transaction_manager.lock().begin_ro(context.snapshot_id);
        Ok(Transaction::new(context, self))
    }

    pub fn state_root(&self) -> B256 {
        self.storage_engine.read_context().root_node_hash
    }

    pub fn size(&self) -> u32 {
        self.storage_engine.size()
    }

    pub fn update_metrics_ro(&self, context: &TransactionContext) {
        self.cfg
            .metrics
            .ro_transaction_pages_read
            .record(context.transaction_metrics.take_pages_read() as f64);

        let (cache_storage_read_hit, cache_storage_read_miss) =
            context.transaction_metrics.take_cache_storage_read();
        self.cfg.metrics.cache_storage_read_hit.increment(cache_storage_read_hit as u64);
        self.cfg.metrics.cache_storage_read_miss.increment(cache_storage_read_miss as u64);
    }

    pub fn update_metrics_rw(&self, context: &TransactionContext) {
        self.cfg
            .metrics
            .rw_transaction_pages_read
            .record(context.transaction_metrics.take_pages_read() as f64);
        self.cfg
            .metrics
            .rw_transaction_pages_allocated
            .record(context.transaction_metrics.take_pages_allocated() as f64);
        self.cfg
            .metrics
            .rw_transaction_pages_reallocated
            .record(context.transaction_metrics.take_pages_reallocated() as f64);
        self.cfg
            .metrics
            .rw_transaction_pages_split
            .record(context.transaction_metrics.take_pages_split() as f64);
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::{account::Account, path::AddressPath};
    use alloy_primitives::{address, Address, U256};
    use alloy_trie::{EMPTY_ROOT_HASH, KECCAK_EMPTY};
    use std::fs;
    use tempdir::TempDir;

    #[test]
    fn test_open() {
        let tmp_dir = TempDir::new("test_db").expect("temporary dir creation failed");
        let db_path = tmp_dir.path().join("db-file");
        let auto_meta_path = tmp_dir.path().join("db-file.meta");
        let custom_meta_path = tmp_dir.path().join("meta-file");

        // Try to open a non-existing database
        Database::options()
            .open(&db_path, &Config::default())
            .expect_err("opening a non-existing database should have failed");
        assert!(!db_path.exists());
        assert!(!auto_meta_path.exists());

        // Open with create(true)
        Database::options()
            .create(true)
            .open(&db_path, &Config::default())
            .expect("database creation should have succeeded");
        assert!(db_path.exists());
        assert!(auto_meta_path.exists());

        // Open again with create_new(true)
        Database::options()
            .create_new(true)
            .open(&db_path, &Config::default())
            .expect_err("database creation should have failed");
        assert!(db_path.exists());
        assert!(auto_meta_path.exists());

        // Remove the files and open with create_new(true)
        fs::remove_file(&db_path).expect("database file removal failed");
        fs::remove_file(&auto_meta_path).expect("metadata file removal failed");
        Database::options()
            .create_new(true)
            .open(&db_path, &Config::default())
            .expect("database creation should have succeeded");
        assert!(db_path.exists());
        assert!(auto_meta_path.exists());

        // Remove all files, and open with a custom metadata path
        fs::remove_file(&db_path).expect("database file removal failed");
        fs::remove_file(&auto_meta_path).expect("metadata file removal failed");
        Database::options()
            .create(true)
            .meta_path(&custom_meta_path)
            .open(&db_path, &Config::default())
            .expect("database creation should have succeeded");
        assert!(db_path.exists());
        assert!(custom_meta_path.exists());
        assert!(!auto_meta_path.exists());
    }

    #[test]
    fn test_set_get_account() {
        let tmp_dir = TempDir::new("test_db").unwrap();
        let file_path = tmp_dir.path().join("test.db");
        let db = Database::create_new(file_path, &Config::default()).unwrap();

        let address = address!("0xd8da6bf26964af9d7eed9e03e53415d37aa96045");

        let account1 = Account::new(1, U256::from(100), EMPTY_ROOT_HASH, KECCAK_EMPTY);
        let mut tx = db.begin_rw().unwrap();
        tx.set_account(AddressPath::for_address(address), Some(account1.clone())).unwrap();

        tx.commit().unwrap();

        let account2 = Account::new(456, U256::from(123), EMPTY_ROOT_HASH, KECCAK_EMPTY);
        let mut tx = db.begin_rw().unwrap();
        tx.set_account(AddressPath::for_address(address), Some(account2.clone())).unwrap();

        let mut ro_tx = db.begin_ro().unwrap();
        tx.commit().unwrap();

        // The read transaction was created before the write was committed, so it should not see the
        // changes.
        let read_account = ro_tx.get_account(AddressPath::for_address(address)).unwrap();

        assert_eq!(account1, read_account.unwrap());

        // The writer transaction is committed, so the read transaction should see the changes.
        let mut ro_tx = db.begin_ro().unwrap();

        let read_account = ro_tx.get_account(AddressPath::for_address(address)).unwrap();

        assert_eq!(account2, read_account.unwrap());

        // cleanup
        tmp_dir.close().unwrap();
    }

    #[test]
    fn test_open_resize() {
        // GIVEN: a database
        //
        // create the database on disk. currently this will create a database with 0 pages
        let tmp_dir = TempDir::new("test_db").unwrap();
        let file_path = tmp_dir.path().join("test.db");
        let _db = Database::create_new(&file_path, &Config::default()).unwrap();

        // WHEN: the database is opened
        let db = Database::open(&file_path, &Config::default()).unwrap();

        // THEN: the size of the database should be 0
        assert_eq!(db.size(), 0);

        // cleanup
        tmp_dir.close().unwrap();
    }

    #[test]
    fn test_data_persistence() {
        let tmp_dir = TempDir::new("test_db").unwrap();
        let file_path = tmp_dir.path().join("test.db");
        let db = Database::create_new(&file_path, &Config::default()).unwrap();

        let address1 = address!("0xd8da6bf26964af9d7eed9e03e53415d37aa96045");
        let account1 = Account::new(1, U256::from(100), EMPTY_ROOT_HASH, KECCAK_EMPTY);

        let mut tx = db.begin_rw().unwrap();
        tx.set_account(AddressPath::for_address(address1), Some(account1.clone())).unwrap();

        tx.commit().unwrap();
        db.close().unwrap();

        let db = Database::open(&file_path, &Config::default()).unwrap();
        let mut tx = db.begin_ro().unwrap();
        let account = tx.get_account(AddressPath::for_address(address1)).unwrap().unwrap();
        assert_eq!(account, account1);

        tx.commit().unwrap();

        let address2 = address!("0x1234567890abcdef1234567890abcdef12345678");
        let account2 = Account::new(2, U256::from(200), EMPTY_ROOT_HASH, KECCAK_EMPTY);
        let mut tx = db.begin_rw().unwrap();
        tx.set_account(AddressPath::for_address(address2), Some(account2.clone())).unwrap();

        tx.commit().unwrap();
        db.close().unwrap();

        let db = Database::open(&file_path, &Config::default()).unwrap();
        let mut tx = db.begin_ro().unwrap();

        let account = tx.get_account(AddressPath::for_address(address1)).unwrap().unwrap();
        assert_eq!(account, account1);

        let account = tx.get_account(AddressPath::for_address(address2)).unwrap().unwrap();
        assert_eq!(account, account2);
    }

    #[test]
    fn test_orphan_page_recycling_safety() {
        fn random_accounts(count: usize) -> impl Iterator<Item = (AddressPath, Option<Account>)> {
            (0..count).map(|_| {
                let address = Address::random();
                let account = Account::new(1, U256::from(100), EMPTY_ROOT_HASH, KECCAK_EMPTY);
                (AddressPath::for_address(address), Some(account))
            })
        }

        fn alive_page_ids(db: &Database) -> Vec<PageId> {
            let orphan_pages = db
                .storage_engine
                .meta_manager
                .lock()
                .orphan_pages()
                .iter()
                .map(|orphan| orphan.page_id())
                .collect::<Vec<_>>();
            let all_pages = (1..=db.storage_engine.page_manager.size())
                .map(|page_id| PageId::new(page_id).unwrap());
            all_pages.filter(move |page_id| !orphan_pages.contains(page_id)).collect()
        }

        // Create a new database and verify it has no pages
        let tmp_dir = TempDir::new("test_db").unwrap();
        let file_path = tmp_dir.path().join("test.db");
        let db = Database::create_new(file_path, &Config::default()).unwrap();
        assert_eq!(db.storage_engine.page_manager.size(), 0);

        // Add 1000 accounts
        let mut tx = db.begin_rw().expect("rw transaction creation failed");
        let initial_accounts = random_accounts(1000).collect::<Vec<_>>();
        for (address, account) in &initial_accounts {
            tx.set_account(address.clone(), account.clone()).expect("adding account failed");
        }
        tx.commit().expect("commit failed");

        // Verify that the 1000 accounts got recorded in more than 1 page at snapshot 1
        let page_ids = alive_page_ids(&db);
        assert!(page_ids.len() > 1, "storage has no pages");
        for page_id in &page_ids {
            assert_eq!(
                db.storage_engine
                    .page_manager
                    .get(1, *page_id)
                    .unwrap_or_else(|err| panic!("page {page_id} not found: {err:?}"))
                    .snapshot_id(),
                1
            );
        }

        // Add 1000 more accounts
        let mut tx = db.begin_rw().expect("rw transaction creation failed");
        let more_accounts = random_accounts(1000).collect::<Vec<_>>();
        for (address, account) in &more_accounts {
            tx.set_account(address.clone(), account.clone()).expect("adding account failed");
        }
        tx.commit().expect("commit failed");

        // Verify that the new accounts caused even more pages to get added, this time at snapshot
        // 2
        let old_page_ids = page_ids;
        let new_page_ids = alive_page_ids(&db);
        assert!(
            new_page_ids.len() > old_page_ids.len(),
            "number of pages did not increase: {} -> {}",
            old_page_ids.len(),
            new_page_ids.len()
        );
        for page_id in &new_page_ids {
            let page = db
                .storage_engine
                .page_manager
                .get(1, *page_id)
                .unwrap_or_else(|err| panic!("page {page_id} not found: {err:?}"));
            if old_page_ids.contains(page_id) {
                assert_eq!(page.snapshot_id(), 1);
            } else {
                assert_eq!(page.snapshot_id(), 2);
            }
        }

        // Obtain a read transaction, and verify that it can access all the initial accounts
        let mut read_tx = db.begin_ro().expect("ro transaction creation failed");
        for (address, account) in &initial_accounts {
            assert_eq!(
                read_tx.get_account(address.clone()).expect("error while reading account"),
                account.clone()
            );
        }

        // Delete the initial accounts
        let mut tx = db.begin_rw().expect("rw transaction creation failed");
        for (address, _) in &initial_accounts {
            tx.set_account(address.clone(), None).expect("deleting account failed");
        }
        tx.commit().expect("commit failed");

        // Verify that the read transaction that we created before the delete can still access the
        // initial accounts
        read_tx.clear_cache();
        for (address, account) in &initial_accounts {
            assert_eq!(
                read_tx.get_account(address.clone()).expect("error while reading account"),
                account.clone()
            );
        }
    }
}
